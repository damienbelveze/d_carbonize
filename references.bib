@article{barkerIntroducingFAIRPrinciples2022,
  title = {Introducing the {{FAIR Principles}} for Research Software},
  author = {Barker, Michelle and Chue Hong, Neil P. and Katz, Daniel S. and Lamprecht, Anna-Lena and Martinez-Ortiz, Carlos and Psomopoulos, Fotis and Harrow, Jennifer and Castro, Leyla Jael and Gruenpeter, Morane and Martinez, Paula Andrea and Honeyman, Tom},
  date = {2022-10-14},
  journaltitle = {Scientific Data},
  shortjournal = {Sci Data},
  volume = {9},
  number = {1},
  pages = {622},
  publisher = {Nature Publishing Group},
  issn = {2052-4463},
  doi = {10.1038/s41597-022-01710-x},
  url = {https://www.nature.com/articles/s41597-022-01710-x},
  urldate = {2024-10-14},
  abstract = {Research software is a fundamental and vital part of research, yet significant challenges to discoverability, productivity, quality, reproducibility, and sustainability exist. Improving the practice of scholarship is a common goal of the open science, open source, and FAIR (Findable, Accessible, Interoperable and Reusable) communities and research software is now being understood as a type of digital object to which FAIR should be applied. This emergence reflects a maturation of the research community to better understand the crucial role of FAIR research software in maximising research value. The FAIR for Research Software (FAIR4RS) Working Group has adapted the FAIR Guiding Principles to create the FAIR Principles for Research Software (FAIR4RS Principles). The contents and context of the FAIR4RS Principles are summarised here to provide the basis for discussion of their adoption. Examples of implementation by organisations are provided to share information on how to maximise the value of research outputs, and to encourage others to amplify the importance and impact of this work.},
  langid = {english},
  keywords = {Policy,Research management}
}

@article{brownFixingScienceMeans2024a,
  title = {Fixing Science Means an End to Gaming the System},
  author = {Brown, Nicholas J. L.},
  date = {2024-09-09},
  journaltitle = {PLOS Biology},
  shortjournal = {PLOS Biology},
  volume = {22},
  number = {9},
  pages = {e3002816},
  publisher = {Public Library of Science},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3002816},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3002816},
  urldate = {2024-10-08},
  abstract = {During the last decade, there has been a substantial acceleration in the open science movement. Most people would probably hope to have seen signs of positive change in that time, yet it seems that the process of improving the practice of science is moving at a glacial pace.},
  langid = {english},
  keywords = {Aviation,Games,Open science,Psychological and psychosocial issues,Reproducibility,Scientific publishing,Scientists,Wheat}
}

@article{colavizzaCitationAdvantageLinking2020a,
  title = {The Citation Advantage of Linking Publications to Research Data},
  author = {Colavizza, Giovanni and Hrynaszkiewicz, Iain and Staden, Isla and Whitaker, Kirstie and McGillivray, Barbara},
  date = {2020-04-22},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  volume = {15},
  number = {4},
  pages = {e0230416},
  publisher = {Public Library of Science},
  issn = {1932-6203},
  doi = {10.1371/journal.pone.0230416},
  url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0230416},
  urldate = {2024-10-12},
  abstract = {Efforts to make research results open and reproducible are increasingly reflected by journal policies encouraging or mandating authors to provide data availability statements. As a consequence of this, there has been a strong uptake of data availability statements in recent literature. Nevertheless, it is still unclear what proportion of these statements actually contain well-formed links to data, for example via a URL or permanent identifier, and if there is an added value in providing such links. We consider 531, 889 journal articles published by PLOS and BMC, develop an automatic system for labelling their data availability statements according to four categories based on their content and the type of data availability they display, and finally analyze the citation advantage of different statement categories via regression. We find that, following mandated publisher policies, data availability statements become very common. In 2018 93.7\% of 21,793 PLOS articles and 88.2\% of 31,956 BMC articles had data availability statements. Data availability statements containing a link to data in a repository—rather than being available on request or included as supporting information files—are a fraction of the total. In 2017 and 2018, 20.8\% of PLOS publications and 12.2\% of BMC publications provided DAS containing a link to data in a repository. We also find an association between articles that include statements that link to data in a repository and up to 25.36\% (± 1.07\%) higher citation impact on average, using a citation prediction model. We discuss the potential implications of these results for authors (researchers) and journal publishers who make the effort of sharing their data in repositories. All our data and code are made available in order to reproduce and extend our results.},
  langid = {english},
  keywords = {Bibliometrics,Citation analysis,Data management,Open access publishing,Reproducibility,Science policy,Scientific publishing,Support vector machines}
}

@article{dicosmoCuratedArchivingResearch2020,
  title = {Curated {{Archiving}} of {{Research Software Artifacts}}: {{Lessons Learned}} from the {{French Open Archive}} ({{HAL}})},
  shorttitle = {Curated {{Archiving}} of {{Research Software Artifacts}}},
  author = {Di Cosmo, Roberto and Gruenpeter, Morane and Marmol, Bruno and Monteil, Alain and Romary, Laurent and Sadowska, Jozefina},
  date = {2020-08-05},
  journaltitle = {International Journal of Digital Curation},
  shortjournal = {International Journal of Digital Curation},
  volume = {15},
  pages = {16},
  doi = {10.2218/ijdc.v15i1.698},
  abstract = {Software has become an indissociable support of technical and scientific knowledge. The preservation of this universal body of knowledge is as essential as preserving research articles and data sets. In the quest to make scientific results reproducible, and pass knowledge to future generations, we must preserve these three main pillars: research articles that describe the results, the data sets used or produced, and the software that embodies the logic of the data transformation. The collaboration between Software Heritage (SWH), the Center for Direct Scientific Communication (CCSD) and the scientific and technical information services (IES) of The French Institute for Research in Computer Science and Automation (Inria) has resulted in a specified moderation and curation workflow for research software artifacts deposited in the HAL the French global open access repository. The curation workflow was developed to help digital librarians and archivists handle this new and peculiar artifact - software source code. While implementing the workflow, a set of guidelines has emerged from the challenges and the solutions put in place to help all actors involved in the process.}
}

@article{gabelicaManyResearchersWere2022a,
  title = {Many Researchers Were Not Compliant with Their Published Data Sharing Statement: Mixed-Methods Study},
  shorttitle = {Many Researchers Were Not Compliant with Their Published Data Sharing Statement},
  author = {Gabelica, Mirko and Bojčić, Ružica and Puljak, Livia},
  date = {2022-05-29},
  journaltitle = {Journal of Clinical Epidemiology},
  shortjournal = {Journal of Clinical Epidemiology},
  volume = {0},
  number = {0},
  publisher = {Elsevier},
  issn = {0895-4356, 1878-5921},
  doi = {10.1016/j.jclinepi.2022.05.019},
  url = {https://www.jclinepi.com/article/S0895-4356(22)00141-X/abstract},
  urldate = {2022-06-07},
  abstract = {{$<$}h2{$>$}Abstract{$<$}/h2{$><$}h3{$>$}Objectives{$<$}/h3{$><$}p{$>$}To analyse researchers' compliance with their Data Availability Statement (DAS) from manuscripts published in open access journals with the mandatory DAS.{$<$}/p{$><$}h3{$>$}Study Design and Setting{$<$}/h3{$><$}p{$>$}We analyzed all articles from 333 open-access journals published during January 2019 by BioMed Central. We categorized types of DAS. We surveyed corresponding authors who wrote in DAS that they would share the data. A consent to participate in the study was sought for all included manuscripts. After accessing raw data sets, we checked whether data were available in a way that enabled re-analysis.{$<$}/p{$><$}h3{$>$}Results{$<$}/h3{$><$}p{$>$}Of 3556 analyzed articles, 3416 contained DAS. The most frequent DAS category (42\%) indicated that the datasets are available on reasonable request. Among 1792 manuscripts in which DAS indicated that authors are willing to share their data, 1670 (93\%) authors either did not respond or declined to share their data with us. Among 254 (14\%) of 1792 authors who responded to our query for data sharing, only 122 (6.8\%) provided the requested data.{$<$}/p{$><$}h3{$>$}Conclusion{$<$}/h3{$><$}p{$>$}Even when authors indicate in their manuscript that they will share data upon request, the compliance rate is the same as for authors who do not provide DAS, suggesting that DAS may not be sufficient to ensure data sharing.{$<$}/p{$>$}},
  langid = {english}
}

@book{gorgolewskiPracticalGuideImproving2016,
  title = {A Practical Guide for Improving Transparency and Reproducibility in Neuroimaging Research},
  author = {Gorgolewski, Krzysztof and Poldrack, Russell},
  date = {2016-04-12},
  doi = {10.1101/039354},
  abstract = {Recent years have seen an increase in alarming signals regarding the lack of replicability in neuroscience, psychology, and other related fields. To avoid a widespread crisis in neuroimaging research and consequent loss of credibility in the public eye, we need to improve how we do science. This article aims to be a practical guide for researchers at any stage of their careers that will help them make their research more reproducible and transparent while minimizing the additional effort that this might require. The guide covers three major topics in open science (data, code, and publications) and offers practical advice as well as highlighting advantages of adopting more open research practices that go beyond improved transparency and reproducibility.}
}

@article{jean-quartierSharingPracticesSoftware2024a,
  title = {Sharing Practices of Software Artefacts and Source Code for Reproducible Research},
  author = {Jean-Quartier, Claire and Jeanquartier, Fleur and Stryeck, Sarah and Simon, Jörg and Söser, Birgit and Hasani-Mavriqi, Ilire},
  date = {2024-08-11},
  journaltitle = {International Journal of Data Science and Analytics},
  shortjournal = {Int J Data Sci Anal},
  issn = {2364-4168},
  doi = {10.1007/s41060-024-00617-7},
  url = {https://doi.org/10.1007/s41060-024-00617-7},
  urldate = {2024-09-19},
  abstract = {While source code of software and algorithms depicts an essential component in all fields of modern research involving data analysis and processing steps, it is uncommonly shared upon publication of results throughout disciplines. Simple guidelines to generate reproducible source code have been published. Still, code optimization supporting its repurposing to different settings is often neglected and even less thought of to be registered in catalogues for a public reuse. Though all research output should be reasonably curated in terms of reproducibility, it has been shown that researchers are frequently non-compliant with availability statements in their publications. These do not even include the use of persistent unique identifiers that would allow referencing archives of code artefacts at certain versions and time for long-lasting links to research articles. In this work, we provide an analysis on current practices of authors in open scientific journals in regard to code availability indications, FAIR principles applied to code and algorithms. We present common repositories of choice among authors. Results further show disciplinary differences of code availability in scholarly publications over the past years. We advocate proper description, archiving and referencing of source code and methods as part of the scientific knowledge, also appealing to editorial boards and reviewers for supervision.},
  langid = {english},
  keywords = {Artificial Intelligence,FAIR principles,Open science,Reproducibility,Software availability,Source code}
}

@online{nathanOverviewDataGovernance2019a,
  title = {Overview of {{Data Governance}}},
  author = {Nathan, Paco},
  date = {2019-03-24},
  url = {https://derwen.ai/s/6fqt},
  urldate = {2023-01-09},
  abstract = {Data governance is an almost overwhelming topic. This talk surveys history, themes, plus a survey of tools, process, standards, etc. Mistakes imply data quality issues, lack of availability, and other risks that prevent leveraging data. OTOH, compliance issues aim to preventing risks of leveraging data inappropriately. Ultimately, risk management plays the 'thin edge of the wedge' in enterprise.},
  langid = {english},
  organization = {Derwen, Inc.}
}

@article{shanahanRethinkingFAIRData2022a,
  title = {Rethinking the {{A}} in {{FAIR Data}}: {{Issues}} of {{Data Access}} and {{Accessibility}} in {{Research}}},
  shorttitle = {Rethinking the {{A}} in {{FAIR Data}}},
  author = {Shanahan, Hugh and Bezuidenhout, Louise},
  date = {2022-07-27},
  journaltitle = {Frontiers in Research Metrics and Analytics},
  shortjournal = {Front. Res. Metr. Anal.},
  volume = {7},
  publisher = {Frontiers},
  issn = {2504-0537},
  doi = {10.3389/frma.2022.912456},
  url = {https://www.frontiersin.org/articles/10.3389/frma.2022.912456},
  urldate = {2024-04-21},
  abstract = {The FAIR data principles are rapidly becoming a standard through which to assess responsible and reproducible research. In contrast to the requirements associated with the Interoperability principle, the requirements associated with the Accessibility principle are often assumed to be relatively straightforward to implement. Indeed, a variety of different tools assessing FAIR rely on the data being deposited in a trustworthy digital repository. In this paper we note that there is an implicit assumption that access to a repository is independent of where the user is geographically located. Using a virtual personal network (VPN) service we find that access to a set of web sites that underpin Open Science is variable from a set of 14 countries; either through connectivity issues (i.e. connections to download HTML being dropped) or through direct blocking (i.e. web servers sending 403 error codes). Many of the countries included in this study are already marginalized from Open Science discussions due to political issues or infrastructural challenges. This study clearly indicates that access to FAIR data resources is influenced by a range of geo-political factors. Given the volatile nature of politics and the slow pace of infrastructural investment, this is likely to continue to be an issue and indeed may grow. We propose that it is essential for discussions and implementations of FAIR to include awareness of these issues of accessibility. Without this awareness, the expansion of FAIR data may unintentionally reinforce current access inequities and research inequalities around the globe.},
  langid = {english}
}

@article{ziemannFivePillarsComputational2023,
  title = {The Five Pillars of Computational Reproducibility: Bioinformatics and Beyond},
  shorttitle = {The Five Pillars of Computational Reproducibility},
  author = {Ziemann, Mark and Poulain, Pierre and Bora, Anusuiya},
  date = {2023-11-01},
  journaltitle = {Briefings in Bioinformatics},
  shortjournal = {Briefings in Bioinformatics},
  volume = {24},
  number = {6},
  pages = {bbad375},
  issn = {1477-4054},
  doi = {10.1093/bib/bbad375},
  url = {https://doi.org/10.1093/bib/bbad375},
  urldate = {2023-10-26},
  abstract = {Computational reproducibility is a simple premise in theory, but is difficult to achieve in practice. Building upon past efforts and proposals to maximize reproducibility and rigor in bioinformatics, we present a framework called the five pillars of reproducible computational research. These include (1) literate programming, (2) code version control and sharing, (3) compute environment control, (4) persistent data sharing and (5) documentation. These practices will ensure that computational research work can be reproduced quickly and easily, long into the future. This guide is designed for bioinformatics data analysts and bioinformaticians in training, but should be relevant to other domains of study.}
}
